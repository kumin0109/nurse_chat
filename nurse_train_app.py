import os
import json
import hashlib
import random
from typing import Dict, Any, List, Tuple

import numpy as np
import pandas as pd
import streamlit as st
from numpy import dot, linalg
from openai import OpenAI

# ==================== í™˜ê²½ ë³€ìˆ˜ ë° OpenAI ì´ˆê¸°í™” ====================
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
EXCEL_PATH = os.getenv("EXCEL_PATH", "")  # ë¹„ì›Œë‘ë©´ ìë™íƒìƒ‰ (í˜„ì¬ëŠ” ë¯¸ì‚¬ìš©)
client = OpenAI(api_key=OPENAI_API_KEY)

# ==================== ì „ì—­ ì„¤ì • ====================
TARGET_SHEETS = ["ë³‘ë™ë¶„ë§Œì‹¤", "ë³‘ë™ë³„ ê³ ê° ì‘ëŒ€"]  # í—ˆìš© ì¹´í…Œê³ ë¦¬(ì‹œíŠ¸)

# ==================== ì„ë² ë”© ìºì‹œ ====================
def _emb_cache_path() -> str:
    return "/tmp/_emb_cache.json"

def _load_emb_cache() -> Dict[str, List[float]]:
    path = _emb_cache_path()
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}

def _save_emb_cache(cache: Dict[str, List[float]]) -> None:
    try:
        with open(_emb_cache_path(), "w", encoding="utf-8") as f:
            json.dump(cache, f)
    except Exception:
        pass

def _hash_text(text: str) -> str:
    return hashlib.sha1(text.encode("utf-8")).hexdigest()

def get_embedding(text: str) -> List[float]:
    resp = client.embeddings.create(input=text, model="text-embedding-3-large")
    return resp.data[0].embedding

def safe_get_embedding(text: str, max_len: int = 2000) -> List[float]:
    if not text:
        text = " "
    if len(text) > max_len:
        text = text[:max_len]
    cache = _load_emb_cache()
    key = _hash_text(text)
    if key in cache:
        return cache[key]
    emb = get_embedding(text)
    cache[key] = emb
    _save_emb_cache(cache)
    return emb

# ==================== ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ====================
def cos_sim(A: np.ndarray, B: np.ndarray) -> float:
    denom = (linalg.norm(A) * linalg.norm(B))
    if denom == 0:
        return 0.0
    return float(dot(A, B) / denom)

# ==================== ì—‘ì…€ ë°ì´í„° ë¡œë“œ ====================
def _pick(row: pd.Series, candidates: List[str], default: str = "") -> str:
    """ì—¬ëŸ¬ í›„ë³´ ì»¬ëŸ¼ëª… ì¤‘ ì¡´ì¬í•˜ê³  ê°’ì´ ìˆëŠ” ì²« í•­ëª©ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜"""
    for name in candidates:
        if name in row.index:
            val = row[name]
            if pd.notna(val) and str(val).strip():
                return str(val).strip()
    return default

@st.cache_data(show_spinner=True)
def load_quiz_data() -> Tuple[Dict[str, pd.DataFrame], List[str], List[Dict[str, Any]]]:
    """
    í…”ë ˆê·¸ë¨ ë²„ì „ê³¼ ë™ì¼í•œ ì»¬ëŸ¼ ë§¤í•‘ ìœ ì§€:
    - ìƒí™©: ["ìƒí™©", "ìƒí™© ì„¤ëª…", "ìƒí™©ë‚´ìš©"]
    - ì§ˆë¬¸: ["ì§ˆë¬¸", "ì§ˆì˜", "ë¬¸ì œ"]
    - ëª¨ë²”ë‹µì•ˆ: ["ëª¨ë²”ë‹µì•ˆ", "ëª¨ë²”ë‹µë³€", "í‘œì¤€ë‹µë³€"]
    """
    REAL_EXCEL = "nursing_data.xlsx"   # ê°™ì€ í´ë”ì— ìˆëŠ” íŒŒì¼ ê³ ì •
    xls = pd.ExcelFile(REAL_EXCEL, engine="openpyxl")
    data_dict: Dict[str, pd.DataFrame] = {}

    for sheet in xls.sheet_names:
        df = pd.read_excel(REAL_EXCEL, sheet_name=sheet, engine="openpyxl")
        df.columns = [str(c).strip() for c in df.columns]  # ì»¬ëŸ¼ ê³µë°± ì œê±°
        data_dict[sheet] = df

    all_problems: List[Dict[str, Any]] = []
    for sheet, df in data_dict.items():
        for idx, row in df.iterrows():
            pid = f"{sheet}_{idx}"
            situation = _pick(row, ["ìƒí™©", "ìƒí™© ì„¤ëª…", "ìƒí™©ë‚´ìš©"], default="")
            question = _pick(row, ["ì§ˆë¬¸", "ì§ˆì˜", "ë¬¸ì œ"], default="")
            standard_answer = _pick(row, ["ëª¨ë²”ë‹µì•ˆ", "ëª¨ë²”ë‹µë³€", "í‘œì¤€ë‹µë³€"], default="")
            all_problems.append({
                "id": pid,
                "sheet": sheet,
                "situation": situation,
                "question": question,
                "standard_answer": standard_answer,
                "embedding": None,
            })
    return data_dict, xls.sheet_names, all_problems

def _ensure_problem_embedding(problem: Dict[str, Any]) -> List[float]:
    if problem.get("embedding") is None:
        problem["embedding"] = safe_get_embedding(problem["standard_answer"])
    return problem["embedding"]

# ==================== ë¬¸ì œ ì¶”ì¶œ ====================
def _allowed_categories(sheet_names: List[str]) -> List[str]:
    filtered = [s for s in sheet_names if s in TARGET_SHEETS]
    return filtered if filtered else list(sheet_names)

def get_random_problem(all_problems: List[Dict[str, Any]], category: str | None = None) -> Dict[str, Any] | None:
    try:
        if category and category != "ì „ì²´":
            filtered = [p for p in all_problems if p["sheet"] == category]
            return random.choice(filtered) if filtered else None
        return random.choice(all_problems) if all_problems else None
    except Exception:
        return None

# ==================== GPT í‰ê°€ í”„ë¡¬í”„íŠ¸ ====================
def create_evaluation_prompt(user_answer: str, problem: Dict[str, Any], similarity: float) -> str:
    return f"""
ë„ˆëŠ” ê°„í˜¸ êµìœ¡ í‰ê°€ìœ„ì›ì´ë‹¤. ì•„ë˜ í•™ìƒ ë‹µë³€ì„ ê°„ë‹¨íˆ í‰ê°€í•´ë¼.

[ì¶œë ¥ í˜•ì‹]
í”¼ë“œë°±: í•™ìƒ ë‹µë³€ì— ëŒ€í•œ ì§§ì€ ì´í‰ (2~3ë¬¸ì¥)

ì¥ì :
- 1~2ê°œ bullet point

ë‹¨ì :
- 1~2ê°œ bullet point

ì ìˆ˜:
- 0~100ì  ì‚¬ì´ ì •ìˆ˜ 1ê°œ

ê°œì„  ë‹µë³€:
- í•™ìƒ ë‹µë³€ì„ ê°„ë‹¨íˆ ë³´ì™„í•œ ì˜ˆì‹œ (ì§§ê²Œ)

[ìƒí™©]
{problem['situation']}

[ì§ˆë¬¸]
{problem['question']}

[í‘œì¤€ë‹µë³€]
{problem['standard_answer']}

[í•™ìƒ ë‹µë³€]
{user_answer}

[ìœ ì‚¬ë„ ì ìˆ˜]
{similarity:.2f}
"""

def generate_evaluation(prompt: str) -> str:
    try:
        result = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ê°„í˜¸ êµìœ¡ ì „ë¬¸ê°€ì´ë©° í‰ê°€ìœ„ì›ì´ë‹¤."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            max_tokens=400,
        )
        return result.choices[0].message.content
    except Exception as e:
        print(f"GPT ì˜¤ë¥˜: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì±„ì  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ==================== Streamlit UI ====================
st.set_page_config(page_title="ê°„í˜¸ì‚¬ êµìœ¡ ì±—ë´‡ (ì—‘ì…€ ê¸°ë°˜)", page_icon="ğŸ©º", layout="centered")
st.title("ğŸ©º ê°„í˜¸ì‚¬ êµìœ¡ ì±—ë´‡")
st.caption("ë°ì´í„° ì†ŒìŠ¤: Excel íŒŒì¼ (DB ì—†ì´ ë™ì‘)")

# ë°ì´í„° ë¡œë“œ
try:
    data_dict, sheet_names, all_problems = load_quiz_data()
    st.caption(f"ë°ì´í„° ì‹œíŠ¸: {', '.join(sheet_names)}")
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {type(e).__name__}: {str(e)[:200]}")
    st.stop()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "category" not in st.session_state:
    st.session_state.category = None
if "problem_id" not in st.session_state:
    st.session_state.problem_id = None
if "last_feedback" not in st.session_state:
    st.session_state.last_feedback = ""
if "last_problem" not in st.session_state:
    st.session_state.last_problem = None
if "prev_category" not in st.session_state:
    st.session_state.prev_category = None  # UI ì „í™˜ìš©
if "user_answer" not in st.session_state:
    st.session_state.user_answer = ""      # âœ¨ ì…ë ¥ ìœ ì§€/ì´ˆê¸°í™”ìš©

# ì¹´í…Œê³ ë¦¬ ì„ íƒ (ì „ì²´ + í—ˆìš© ì‹œíŠ¸ ë‘ ê°œ)
allowed = ["ì „ì²´"] + _allowed_categories(list(sheet_names))
st.subheader("ì¹´í…Œê³ ë¦¬ ì„ íƒ")
# Streamlit 1.33+ segmented_control, ê·¸ ì´í•˜ ë²„ì „ì´ë©´ radioë¡œ êµì²´ ê°€ëŠ¥
try:
    category = st.segmented_control("ë¬¸ì œë¥¼ í’€ ì¹´í…Œê³ ë¦¬", options=allowed, default=allowed[0], help="ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
except Exception:
    category = st.radio("ë¬¸ì œë¥¼ í’€ ì¹´í…Œê³ ë¦¬", options=allowed, index=0, help="ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
st.session_state.category = category

# ì¹´í…Œê³ ë¦¬ê°€ ë°”ë€Œë©´ ìƒíƒœ ì´ˆê¸°í™” (ë²„íŠ¼ ë¼ë²¨ 'ìƒˆ ë¬¸ì œ'ë¡œ ë¦¬ì…‹ + ì…ë ¥ì°½ ë¹„ì›€)
if st.session_state.prev_category != category:
    st.session_state.prev_category = category
    st.session_state.problem_id = None
    st.session_state.last_problem = None
    st.session_state.last_feedback = ""
    st.session_state.user_answer = ""      # âœ¨ ë¹„ìš°ê¸°

col_a, col_b = st.columns(2)

# â¬‡ï¸ ì²˜ìŒì—” 'ğŸ² ìƒˆ ë¬¸ì œ ë°›ê¸°', ì´í›„ì—” 'â¡ï¸ ë‹¤ìŒ ë¬¸ì œ'ë¡œ ìë™ ì „í™˜
main_btn_label = "ğŸ² ìƒˆ ë¬¸ì œ ë°›ê¸°" if st.session_state.last_problem is None else "â¡ï¸ ë‹¤ìŒ ë¬¸ì œ"

with col_a:
    if st.button(main_btn_label, use_container_width=True):
        prob = get_random_problem(all_problems, st.session_state.category)
        if not prob:
            st.warning("âš ï¸ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ë¬¸ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.session_state.problem_id = prob["id"]
            st.session_state.last_problem = prob
            st.session_state.last_feedback = ""
            st.session_state.user_answer = ""  # âœ¨ ë‹¤ìŒ ë¬¸ì œ ë°›ì„ ë•Œ ì…ë ¥ì°½ ë¹„ìš°ê¸°

with col_b:
    if st.button("ğŸ”„ ì¹´í…Œê³ ë¦¬ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.category = allowed[0]
        st.session_state.prev_category = allowed[0]
        st.session_state.problem_id = None
        st.session_state.last_problem = None
        st.session_state.last_feedback = ""
        st.session_state.user_answer = ""      # âœ¨ ë¹„ìš°ê¸°

# í˜„ì¬ ë¬¸ì œ í‘œì‹œ (í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í¬ë§· ìœ ì§€)
st.divider()
st.subheader("ë¬¸ì œ")
if st.session_state.last_problem:
    p = st.session_state.last_problem
    st.markdown(f"**ğŸ“ ë¶€ì„œ:** {p['sheet']}")
    st.markdown(f"**ğŸ“‹ ìƒí™©:** {p['situation'] or '-'}")
    st.markdown(f"**â“ ì§ˆë¬¸:** {p['question'] or '-'}")
else:
    st.info("ì¢Œì¸¡ ìƒë‹¨ì˜ **â€˜ğŸ² ìƒˆ ë¬¸ì œ ë°›ê¸°â€™**ë¥¼ ëˆŒëŸ¬ ì‹œì‘í•˜ì„¸ìš”.")

# ë‹µì•ˆ ì…ë ¥
st.subheader("ë‚˜ì˜ ë‹µë³€")
user_answer = st.text_area(
    "ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”",
    height=160,
    placeholder="ì˜ˆ) ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œì„¤íŒ€ ì ê²€ì„ ìš”ì²­í•˜ê³ , ì˜ˆìƒ ì†Œìš”ì‹œê°„ì„ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤...",
    key="user_answer"  # âœ¨ ì„¸ì…˜ ìƒíƒœë¡œ ê´€ë¦¬
)

# ì±„ì  (ìœ ì‚¬ë„ â†’ GPT í‰ê°€, í…”ë ˆê·¸ë¨ê³¼ ë™ì¼ ë¡œì§)
if st.button("âœ… ì±„ì í•˜ê¸°", type="primary"):
    if not st.session_state.last_problem:
        st.warning("ë¨¼ì € **â€˜ğŸ² ìƒˆ ë¬¸ì œ ë°›ê¸°â€™**ë¥¼ ëˆŒëŸ¬ ë¬¸ì œë¥¼ ë°›ì•„ì£¼ì„¸ìš”.")
    elif not user_answer.strip():
        st.warning("ë‹µë³€ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        try:
            user_emb = safe_get_embedding(user_answer)
            std_emb = _ensure_problem_embedding(st.session_state.last_problem)
            similarity = cos_sim(np.array(user_emb), np.array(std_emb))
            prompt = create_evaluation_prompt(user_answer, st.session_state.last_problem, similarity)
            feedback = generate_evaluation(prompt)
            st.session_state.last_feedback = feedback
            st.success("ì±„ì  ì™„ë£Œ!")
        except Exception as e:
            st.error(f"ì±„ì  ì˜¤ë¥˜: {type(e).__name__}: {str(e)[:200]}")

# ê²°ê³¼ í‘œì‹œ (í…”ë ˆê·¸ë¨ì˜ ì±„ì  ë‹µì¥ í¬ë§· ê·¸ëŒ€ë¡œ)
if st.session_state.last_feedback:
    st.subheader("ğŸ“Š ì±„ì  ê²°ê³¼")
    st.markdown(st.session_state.last_feedback)

# (ì˜µì…˜) ë””ë²„ê·¸
with st.expander("ğŸ” ë””ë²„ê·¸(ì˜µì…˜)"):
    st.write("í˜„ì¬ ì¹´í…Œê³ ë¦¬:", st.session_state.category)
    st.write("í˜„ì¬ ë¬¸ì œ ID:", st.session_state.problem_id)
    st.write("í˜„ì¬ ì…ë ¥ê°’:", st.session_state.user_answer)  # í™•ì¸ìš©
    if st.session_state.last_problem:
        st.json({
            "sheet": st.session_state.last_problem["sheet"],
            "situation": st.session_state.last_problem["situation"],
            "question": st.session_state.last_problem["question"],
        })

