import os
import json
import hashlib
from typing import Dict, Any, List, Tuple

import numpy as np
import pandas as pd
import streamlit as st
from numpy import dot, linalg
from openai import OpenAI

# ==================== í™˜ê²½ ë³€ìˆ˜ ë° OpenAI ì´ˆê¸°í™” ====================
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
EXCEL_PATH = os.getenv("EXCEL_PATH", "")
client = OpenAI(api_key=OPENAI_API_KEY)

# ==================== ì „ì—­ ì„¤ì • ====================
TARGET_SHEETS = ["ë³‘ë™ë¶„ë§Œì‹¤", "ë¶ˆí¸ì‚¬í•­ ëŒ€ì²˜"]   # ë¶ˆí¸ì‚¬í•­ ëŒ€ì²˜ëŠ” ì „ì²´ì—ì„œë§Œ ë…¸ì¶œë¨

# ==================== ì„ë² ë”© ìºì‹œ ====================
def _emb_cache_path() -> str:
    return "/tmp/_emb_cache.json"

def _load_emb_cache() -> Dict[str, List[float]]:
    path = _emb_cache_path()
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}

def _save_emb_cache(cache: Dict[str, List[float]]) -> None:
    try:
        with open(_emb_cache_path(), "w", encoding="utf-8") as f:
            json.dump(cache, f)
    except Exception:
        pass

def _hash_text(text: str) -> str:
    return hashlib.sha1(text.encode("utf-8")).hexdigest()

def get_embedding(text: str) -> List[float]:
    resp = client.embeddings.create(input=text, model="text-embedding-3-large")
    return resp.data[0].embedding

def safe_get_embedding(text: str, max_len: int = 2000) -> List[float]:
    if not text:
        text = " "
    if len(text) > max_len:
        text = text[:max_len]
    cache = _load_emb_cache()
    key = _hash_text(text)
    if key in cache:
        return cache[key]
    emb = get_embedding(text)
    cache[key] = emb
    _save_emb_cache(cache)
    return emb

# ==================== ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ====================
def cos_sim(A: np.ndarray, B: np.ndarray) -> float:
    denom = (linalg.norm(A) * linalg.norm(B))
    if denom == 0:
        return 0.0
    return float(dot(A, B) / denom)

# ==================== ì—‘ì…€ ë°ì´í„° ë¡œë“œ ====================
def _pick(row: pd.Series, candidates: List[str], default: str = "") -> str:
    for name in candidates:
        if name in row.index:
            val = row[name]
            if pd.notna(val) and str(val).strip():
                return str(val).strip()
    return default

@st.cache_data(show_spinner=True)
def load_quiz_data() -> List[Dict[str, Any]]:
    REAL_EXCEL = "nursing_data.xlsx"
    xls = pd.ExcelFile(REAL_EXCEL, engine="openpyxl")
    all_problems: List[Dict[str, Any]] = []

    for sheet in xls.sheet_names:
        df = pd.read_excel(REAL_EXCEL, sheet_name=sheet, engine="openpyxl")
        df.columns = [str(c).strip() for c in df.columns]
        sheet_normalized = "ë¶ˆí¸ì‚¬í•­ ëŒ€ì²˜" if sheet in ["ë³‘ë™ë³„ ê³ ê° ì‘ëŒ€", "ë¶ˆí¸ì‚¬í•­ ëŒ€ì²˜"] else sheet

        for idx, row in df.iterrows():
            pid = f"{sheet_normalized}_{idx}"
            situation = _pick(row, ["ìƒí™©", "ìƒí™© ì„¤ëª…", "ìƒí™©ë‚´ìš©"], default="")
            question = _pick(row, ["ì§ˆë¬¸", "ì§ˆì˜", "ë¬¸ì œ"], default="")
            standard_answer = _pick(row, ["ëª¨ë²”ë‹µì•ˆ", "ëª¨ë²”ë‹µë³€", "í‘œì¤€ë‹µë³€"], default="")
            all_problems.append({
                "id": pid,
                "sheet": sheet_normalized,
                "situation": situation,
                "question": question,
                "standard_answer": standard_answer,
                "embedding": None,
            })
    return all_problems

def _ensure_problem_embedding(problem: Dict[str, Any]) -> List[float]:
    if problem.get("embedding") is None:
        problem["embedding"] = safe_get_embedding(problem["standard_answer"])
    return problem["embedding"]

# ==================== GPT í‰ê°€ í”„ë¡¬í”„íŠ¸ ====================
def create_evaluation_prompt(user_answer: str, problem: Dict[str, Any], similarity: float) -> str:
    return f"""
ë„ˆëŠ” ê°„í˜¸ êµìœ¡ í‰ê°€ìœ„ì›ì´ë‹¤. ì•„ë˜ í•™ìƒ ë‹µë³€ì„ ê°„ë‹¨íˆ í‰ê°€í•´ë¼.

[ì¶œë ¥ í˜•ì‹]
í”¼ë“œë°±: í•™ìƒ ë‹µë³€ì— ëŒ€í•œ ì§§ì€ ì´í‰ (2~3ë¬¸ì¥)

ì¥ì :
- 1~2ê°œ bullet point

ë‹¨ì :
- 1~2ê°œ bullet point

ì ìˆ˜:
- 0~100ì  ì‚¬ì´ ì •ìˆ˜ 1ê°œ

ê°œì„  ë‹µë³€:
- í•™ìƒ ë‹µë³€ì„ ê°„ë‹¨íˆ ë³´ì™„í•œ ì˜ˆì‹œ (ì§§ê²Œ)

[ìƒí™©]
{problem['situation']}

[ì§ˆë¬¸]
{problem['question']}

[í‘œì¤€ë‹µë³€]
{problem['standard_answer']}

[í•™ìƒ ë‹µë³€]
{user_answer}

[ìœ ì‚¬ë„ ì ìˆ˜]
{similarity:.2f}
"""

def generate_evaluation(prompt: str) -> str:
    try:
        result = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ê°„í˜¸ êµìœ¡ ì „ë¬¸ê°€ì´ë©° í‰ê°€ìœ„ì›ì´ë‹¤."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            max_tokens=400,
        )
        return result.choices[0].message.content
    except Exception as e:
        return "ì±„ì  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ==================== Streamlit UI ====================
st.set_page_config(page_title="ê°„í˜¸ì‚¬ êµìœ¡ ì±—ë´‡", page_icon="ğŸ©º", layout="centered")
st.title("ğŸ©º ê°„í˜¸ì‚¬ êµìœ¡ ì±—ë´‡")

# ë°ì´í„° ë¡œë“œ
try:
    all_problems = load_quiz_data()
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

# ì„¸ì…˜ ìƒíƒœ
if "category" not in st.session_state:
    st.session_state.category = "ì „ì²´"
if "problem_index" not in st.session_state:
    st.session_state.problem_index = -1  # ì‹œì‘ ì „
if "last_feedback" not in st.session_state:
    st.session_state.last_feedback = ""

# ---------------- ì¹´í…Œê³ ë¦¬ ì„ íƒ ----------------
allowed = ["ì „ì²´", "ë³‘ë™ë¶„ë§Œì‹¤"]
st.subheader("ì¹´í…Œê³ ë¦¬ ì„ íƒ")
category = st.radio("ë¬¸ì œë¥¼ í’€ ì¹´í…Œê³ ë¦¬", options=allowed, index=0)
st.session_state.category = category

# â–¶ï¸ ì‹œì‘í•˜ê¸° ë²„íŠ¼ (ì¹´í…Œê³ ë¦¬ ì„ íƒ ë°‘)
if st.session_state.problem_index == -1:
    if st.button("â–¶ï¸ ì‹œì‘í•˜ê¸°", use_container_width=True):
        st.session_state.problem_index = 0
        st.session_state.last_feedback = ""
        st.rerun()

# ë¬¸ì œ ë¦¬ìŠ¤íŠ¸ í•„í„°ë§
if category == "ë³‘ë™ë¶„ë§Œì‹¤":
    problems = [p for p in all_problems if p["sheet"] == "ë³‘ë™ë¶„ë§Œì‹¤"]
else:
    problems = [p for p in all_problems if p["sheet"] in TARGET_SHEETS]

# ---------------- ë¬¸ì œ í‘œì‹œ ----------------
st.divider()
st.subheader("ë¬¸ì œ")
if 0 <= st.session_state.problem_index < len(problems):
    p = problems[st.session_state.problem_index]
    st.markdown(f"**ğŸ“ ë¶€ì„œ:** {p['sheet']}")
    st.markdown(f"**ğŸ“‹ ìƒí™©:** {p['situation'] or '-'}")
    st.markdown(f"**â“ ì§ˆë¬¸:** {p['question'] or '-'}")
elif st.session_state.problem_index >= len(problems):
    st.success("ğŸ‰ ëª¨ë“  ë¬¸ì œë¥¼ ë‹¤ í’€ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!")

# ---------------- ë‹µì•ˆ ì…ë ¥ ----------------
if 0 <= st.session_state.problem_index < len(problems):
    st.subheader("ë‚˜ì˜ ë‹µë³€")
    current_pid = problems[st.session_state.problem_index]["id"]
    user_answer = st.text_area(
        "ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”",
        height=160,
        key=f"user_answer_{current_pid}"
    )

    # ì±„ì í•˜ê¸°
    if st.button("âœ… ì±„ì í•˜ê¸°", type="primary"):
        problem = problems[st.session_state.problem_index]
        if not user_answer.strip():
            st.warning("ë‹µë³€ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            try:
                user_emb = safe_get_embedding(user_answer)
                std_emb = _ensure_problem_embedding(problem)
                similarity = cos_sim(np.array(user_emb), np.array(std_emb))
                prompt = create_evaluation_prompt(user_answer, problem, similarity)
                feedback = generate_evaluation(prompt)
                st.session_state.last_feedback = feedback
                st.success("ì±„ì  ì™„ë£Œ!")
            except Exception as e:
                st.error(f"ì±„ì  ì˜¤ë¥˜: {e}")

    if st.session_state.last_feedback:
        st.subheader("ğŸ“Š ì±„ì  ê²°ê³¼")
        st.markdown(st.session_state.last_feedback)

    # ë‹¤ìŒ ë¬¸ì œ / ì¹´í…Œê³ ë¦¬ ë³€ê²½
    col1, col2 = st.columns(2)
    with col1:
        if st.button("â¡ï¸ ë‹¤ìŒ ë¬¸ì œ", use_container_width=True):
            st.session_state.problem_index += 1
            st.session_state.last_feedback = ""
            st.rerun()
    with col2:
        if st.button("ğŸ”„ ì¹´í…Œê³ ë¦¬ ë³€ê²½", use_container_width=True):
            st.session_state.category = "ì „ì²´"
            st.session_state.problem_index = -1
            st.session_state.last_feedback = ""
            st.rerun()
